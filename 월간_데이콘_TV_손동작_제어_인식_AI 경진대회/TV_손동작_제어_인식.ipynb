{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/Tv_손동작.zip"
      ],
      "metadata": {
        "id": "2hQ2mULpB3ds"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorchvideo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc9GP7kihTZf",
        "outputId": "fc7a5ecc-6c93-46d1-ceae-dbf64e12d5cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorchvideo\n",
            "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fvcore (from pytorchvideo)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av (from pytorchvideo)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parameterized (from pytorchvideo)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting iopath (from pytorchvideo)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (1.22.4)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (4.65.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (2.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (8.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo) (4.6.3)\n",
            "Collecting portalocker (from iopath->pytorchvideo)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188694 sha256=d0df63cf5ea4551795118eee8e1d356038e28ecfbadc66002e5765c3b73d4b14\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/4e/81/0f72a543be9ed7eb737c95bfc5da4025e73226b44368074ece\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=9879047594fa194b6b7af542807172efd1a2ac7090502df610d24b2c3429b657\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=e5f80245ad318b6a29550793c50001f5f5ff38b5fbff6d31e8d49b85cd234b7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: av, yacs, portalocker, parameterized, iopath, fvcore, pytorchvideo\n",
            "Successfully installed av-10.0.0 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-2.7.0 pytorchvideo-0.1.5 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC3imTBchY2m",
        "outputId": "6c843070-01ec-4208-8c60-e41f4f913add"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import Dict\n",
        "import json\n",
        "import urllib\n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ")\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4U6z3cWhJ23",
        "outputId": "b93eff94-9083-4306-df89-6a532f1dece3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(41) # Seed 고정"
      ],
      "metadata": {
        "id": "9djs_onKhP2H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "side_size = 256\n",
        "mean = [0.45, 0.45, 0.45]\n",
        "std = [0.225, 0.225, 0.225]\n",
        "crop_size = 256\n",
        "num_frames = 32\n",
        "sampling_rate = 1\n",
        "frames_per_second = 30\n",
        "slowfast_alpha = 4\n",
        "num_clips = 10\n",
        "num_crops = 3"
      ],
      "metadata": {
        "id": "rFf2mYgNhhRb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyMJ-acIhikL",
        "outputId": "98e79904-ad39-4cd4-91ec-a5d63c38f6ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESRJ8Fy8hje2",
        "outputId": "e6761d98-af51-4495-bf4a-931d1131b1de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/pytorchvideo/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/SLOWFAST_8x8_R50.pyth\" to /root/.cache/torch/hub/checkpoints/SLOWFAST_8x8_R50.pyth\n",
            "100%|██████████| 264M/264M [00:01<00:00, 209MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (blocks): ModuleList(\n",
              "    (0): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResNetBasicStem(\n",
              "          (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
              "          (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
              "        )\n",
              "        (1): ResNetBasicStem(\n",
              "          (conv): Conv3d(3, 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
              "          (norm): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(8, 16, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(80, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(8, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(32, 64, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (2): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-3): 3 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(32, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-3): 3 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(64, 128, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (3): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(640, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-5): 5 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(64, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-5): 5 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(128, 256, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (4): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(1280, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(128, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): Identity()\n",
              "    )\n",
              "    (5): PoolConcatPathway(\n",
              "      (pool): ModuleList(\n",
              "        (0): AvgPool3d(kernel_size=(8, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
              "        (1): AvgPool3d(kernel_size=(32, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
              "      )\n",
              "    )\n",
              "    (6): ResNetBasicHead(\n",
              "      (dropout): Dropout(p=0.5, inplace=False)\n",
              "      (proj): Linear(in_features=2304, out_features=400, bias=True)\n",
              "      (output_pool): AdaptiveAvgPool3d(output_size=1)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PackPathway(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Transform for converting video frames as a list of tensors.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, frames: torch.Tensor):\n",
        "        fast_pathway = frames\n",
        "        # Perform temporal sampling from the fast pathway.\n",
        "        slow_pathway = torch.index_select(\n",
        "            frames,\n",
        "            1,\n",
        "            torch.linspace(\n",
        "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
        "            ).long(),\n",
        "        )\n",
        "        frame_list = [slow_pathway, fast_pathway]\n",
        "        return frame_list"
      ],
      "metadata": {
        "id": "69PXPrmNhlAN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file,device,transform=None, train=True):\n",
        "        super().__init__()\n",
        "        self.file = file\n",
        "        self.len = len(self.file)\n",
        "        self.device = device\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        self.datalayer = PackPathway()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train :\n",
        "            path = self.file[idx][0]\n",
        "            label = self.file[idx][1]\n",
        "            video = EncodedVideo.from_path(path)\n",
        "            video_data = video.get_clip(start_sec=0, end_sec=1)\n",
        "            video_data = self.transform(video_data)\n",
        "            inputs = video_data[\"video\"]\n",
        "            inputs = [i.to(device) for i in inputs]\n",
        "\n",
        "            return inputs, label\n",
        "        else :\n",
        "            path = self.file[idx]\n",
        "            video = EncodedVideo.from_path(path)\n",
        "            video_data = video.get_clip(start_sec=0, end_sec=1)\n",
        "            video_data = self.transform(video_data)\n",
        "            inputs = video_data[\"video\"]\n",
        "            inputs = [i.to(device) for i in inputs]\n",
        "\n",
        "            return inputs\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "3hrrVUxIhshH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform =  ApplyTransformToKey(\n",
        "    key=\"video\",\n",
        "    transform=Compose(\n",
        "        [\n",
        "            UniformTemporalSubsample(num_frames),\n",
        "            Lambda(lambda x: x/255.0),\n",
        "            NormalizeVideo(mean, std),\n",
        "            ShortSideScale(\n",
        "                size=side_size\n",
        "            ),\n",
        "            CenterCropVideo(crop_size),\n",
        "            PackPathway()\n",
        "        ]\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "8VOrEoNUhure"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "for vid, path, label in train.values :\n",
        "    train_data.append((path, label))\n",
        "\n",
        "for vid, path in test.values :\n",
        "    test_data.append(path)\n",
        "\n",
        "train_dataset = CustomDataset(train_data,device,transform,train=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "test_dataset = CustomDataset(test_data,device,transform,train=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "id": "fH3yJnWvhv--"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(\n",
        "        nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(\n",
        "        nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                    lr=5e-5, correct_bias=False)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7_GrxFVh0ge",
        "outputId": "e8728e4c-9b7f-4dee-c311-079391ab9c3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,101) :\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    print(\"------------TRAIN------------\")\n",
        "    for i, d in enumerate(train_loader):\n",
        "        data, label = d\n",
        "        label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output,label)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    print(\"train_loss:{:.6f}\".format(total_loss/len(train_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w3qYNA1h2Pu",
        "outputId": "d8463224-5dec-4328-8a10-757a9730343b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------TRAIN------------\n",
            "EPOCH: 1\n",
            "train_loss:0.560667\n",
            "------------TRAIN------------\n",
            "EPOCH: 2\n",
            "train_loss:0.052714\n",
            "------------TRAIN------------\n",
            "EPOCH: 3\n",
            "train_loss:0.055538\n",
            "------------TRAIN------------\n",
            "EPOCH: 4\n",
            "train_loss:0.011240\n",
            "------------TRAIN------------\n",
            "EPOCH: 5\n",
            "train_loss:0.014191\n",
            "------------TRAIN------------\n",
            "EPOCH: 6\n",
            "train_loss:0.004451\n",
            "------------TRAIN------------\n",
            "EPOCH: 7\n",
            "train_loss:0.002169\n",
            "------------TRAIN------------\n",
            "EPOCH: 8\n",
            "train_loss:0.001963\n",
            "------------TRAIN------------\n",
            "EPOCH: 9\n",
            "train_loss:0.001257\n",
            "------------TRAIN------------\n",
            "EPOCH: 10\n",
            "train_loss:0.001640\n",
            "------------TRAIN------------\n",
            "EPOCH: 11\n",
            "train_loss:0.000410\n",
            "------------TRAIN------------\n",
            "EPOCH: 12\n",
            "train_loss:0.000630\n",
            "------------TRAIN------------\n",
            "EPOCH: 13\n",
            "train_loss:0.000395\n",
            "------------TRAIN------------\n",
            "EPOCH: 14\n",
            "train_loss:0.000255\n",
            "------------TRAIN------------\n",
            "EPOCH: 15\n",
            "train_loss:0.000183\n",
            "------------TRAIN------------\n",
            "EPOCH: 16\n",
            "train_loss:0.000699\n",
            "------------TRAIN------------\n",
            "EPOCH: 17\n",
            "train_loss:0.000452\n",
            "------------TRAIN------------\n",
            "EPOCH: 18\n",
            "train_loss:0.000215\n",
            "------------TRAIN------------\n",
            "EPOCH: 19\n",
            "train_loss:0.000188\n",
            "------------TRAIN------------\n",
            "EPOCH: 20\n",
            "train_loss:0.000186\n",
            "------------TRAIN------------\n",
            "EPOCH: 21\n",
            "train_loss:0.000115\n",
            "------------TRAIN------------\n",
            "EPOCH: 22\n",
            "train_loss:0.000151\n",
            "------------TRAIN------------\n",
            "EPOCH: 23\n",
            "train_loss:0.000070\n",
            "------------TRAIN------------\n",
            "EPOCH: 24\n",
            "train_loss:0.000161\n",
            "------------TRAIN------------\n",
            "EPOCH: 25\n",
            "train_loss:0.000255\n",
            "------------TRAIN------------\n",
            "EPOCH: 26\n",
            "train_loss:0.000500\n",
            "------------TRAIN------------\n",
            "EPOCH: 27\n",
            "train_loss:0.000140\n",
            "------------TRAIN------------\n",
            "EPOCH: 28\n",
            "train_loss:0.000053\n",
            "------------TRAIN------------\n",
            "EPOCH: 29\n",
            "train_loss:0.000121\n",
            "------------TRAIN------------\n",
            "EPOCH: 30\n",
            "train_loss:0.000180\n",
            "------------TRAIN------------\n",
            "EPOCH: 31\n",
            "train_loss:0.000125\n",
            "------------TRAIN------------\n",
            "EPOCH: 32\n",
            "train_loss:0.000049\n",
            "------------TRAIN------------\n",
            "EPOCH: 33\n",
            "train_loss:0.000027\n",
            "------------TRAIN------------\n",
            "EPOCH: 34\n",
            "train_loss:0.000032\n",
            "------------TRAIN------------\n",
            "EPOCH: 35\n",
            "train_loss:0.000028\n",
            "------------TRAIN------------\n",
            "EPOCH: 36\n",
            "train_loss:0.000030\n",
            "------------TRAIN------------\n",
            "EPOCH: 37\n",
            "train_loss:0.000019\n",
            "------------TRAIN------------\n",
            "EPOCH: 38\n",
            "train_loss:0.000067\n",
            "------------TRAIN------------\n",
            "EPOCH: 39\n",
            "train_loss:0.000021\n",
            "------------TRAIN------------\n",
            "EPOCH: 40\n",
            "train_loss:0.000036\n",
            "------------TRAIN------------\n",
            "EPOCH: 41\n",
            "train_loss:0.000010\n",
            "------------TRAIN------------\n",
            "EPOCH: 42\n",
            "train_loss:0.000014\n",
            "------------TRAIN------------\n",
            "EPOCH: 43\n",
            "train_loss:0.000007\n",
            "------------TRAIN------------\n",
            "EPOCH: 44\n",
            "train_loss:0.000012\n",
            "------------TRAIN------------\n",
            "EPOCH: 45\n",
            "train_loss:0.000019\n",
            "------------TRAIN------------\n",
            "EPOCH: 46\n",
            "train_loss:0.000051\n",
            "------------TRAIN------------\n",
            "EPOCH: 47\n",
            "train_loss:0.000060\n",
            "------------TRAIN------------\n",
            "EPOCH: 48\n",
            "train_loss:0.000016\n",
            "------------TRAIN------------\n",
            "EPOCH: 49\n",
            "train_loss:0.000006\n",
            "------------TRAIN------------\n",
            "EPOCH: 50\n",
            "train_loss:0.000033\n",
            "------------TRAIN------------\n",
            "EPOCH: 51\n",
            "train_loss:0.000011\n",
            "------------TRAIN------------\n",
            "EPOCH: 52\n",
            "train_loss:0.000015\n",
            "------------TRAIN------------\n",
            "EPOCH: 53\n",
            "train_loss:0.000007\n",
            "------------TRAIN------------\n",
            "EPOCH: 54\n",
            "train_loss:0.000009\n",
            "------------TRAIN------------\n",
            "EPOCH: 55\n",
            "train_loss:0.000011\n",
            "------------TRAIN------------\n",
            "EPOCH: 56\n",
            "train_loss:0.000008\n",
            "------------TRAIN------------\n",
            "EPOCH: 57\n",
            "train_loss:0.000005\n",
            "------------TRAIN------------\n",
            "EPOCH: 58\n",
            "train_loss:0.000004\n",
            "------------TRAIN------------\n",
            "EPOCH: 59\n",
            "train_loss:0.000009\n",
            "------------TRAIN------------\n",
            "EPOCH: 60\n",
            "train_loss:0.000017\n",
            "------------TRAIN------------\n",
            "EPOCH: 61\n",
            "train_loss:0.000004\n",
            "------------TRAIN------------\n",
            "EPOCH: 62\n",
            "train_loss:0.000002\n",
            "------------TRAIN------------\n",
            "EPOCH: 63\n",
            "train_loss:0.000006\n",
            "------------TRAIN------------\n",
            "EPOCH: 64\n",
            "train_loss:0.000001\n",
            "------------TRAIN------------\n",
            "EPOCH: 65\n",
            "train_loss:0.000002\n",
            "------------TRAIN------------\n",
            "EPOCH: 66\n",
            "train_loss:0.000003\n",
            "------------TRAIN------------\n",
            "EPOCH: 67\n",
            "train_loss:0.000004\n",
            "------------TRAIN------------\n",
            "EPOCH: 68\n",
            "train_loss:0.000003\n",
            "------------TRAIN------------\n",
            "EPOCH: 69\n",
            "train_loss:0.000002\n",
            "------------TRAIN------------\n",
            "EPOCH: 70\n",
            "train_loss:0.000003\n",
            "------------TRAIN------------\n",
            "EPOCH: 71\n",
            "train_loss:0.000008\n",
            "------------TRAIN------------\n",
            "EPOCH: 72\n",
            "train_loss:0.000005\n",
            "------------TRAIN------------\n",
            "EPOCH: 73\n",
            "train_loss:0.000003\n",
            "------------TRAIN------------\n",
            "EPOCH: 74\n",
            "train_loss:0.000002\n",
            "------------TRAIN------------\n",
            "EPOCH: 75\n",
            "train_loss:0.000003\n",
            "------------TRAIN------------\n",
            "EPOCH: 76\n",
            "train_loss:0.000003\n",
            "------------TRAIN------------\n",
            "EPOCH: 77\n",
            "train_loss:0.000001\n",
            "------------TRAIN------------\n",
            "EPOCH: 78\n",
            "train_loss:0.000001\n",
            "------------TRAIN------------\n",
            "EPOCH: 79\n",
            "train_loss:0.000002\n",
            "------------TRAIN------------\n",
            "EPOCH: 80\n",
            "train_loss:0.000001\n",
            "------------TRAIN------------\n",
            "EPOCH: 81\n",
            "train_loss:0.000005\n",
            "------------TRAIN------------\n",
            "EPOCH: 82\n",
            "train_loss:0.000001\n",
            "------------TRAIN------------\n",
            "EPOCH: 83\n",
            "train_loss:0.000001\n",
            "------------TRAIN------------\n",
            "EPOCH: 84\n",
            "train_loss:0.000006\n",
            "------------TRAIN------------\n",
            "EPOCH: 85\n",
            "train_loss:0.000003\n",
            "------------TRAIN------------\n",
            "EPOCH: 86\n",
            "train_loss:0.000002\n",
            "------------TRAIN------------\n",
            "EPOCH: 87\n",
            "train_loss:0.100555\n",
            "------------TRAIN------------\n",
            "EPOCH: 88\n",
            "train_loss:0.114382\n",
            "------------TRAIN------------\n",
            "EPOCH: 89\n",
            "train_loss:0.081055\n",
            "------------TRAIN------------\n",
            "EPOCH: 90\n",
            "train_loss:0.003707\n",
            "------------TRAIN------------\n",
            "EPOCH: 91\n",
            "train_loss:0.005714\n",
            "------------TRAIN------------\n",
            "EPOCH: 92\n",
            "train_loss:0.001249\n",
            "------------TRAIN------------\n",
            "EPOCH: 93\n",
            "train_loss:0.000899\n",
            "------------TRAIN------------\n",
            "EPOCH: 94\n",
            "train_loss:0.000521\n",
            "------------TRAIN------------\n",
            "EPOCH: 95\n",
            "train_loss:0.000486\n",
            "------------TRAIN------------\n",
            "EPOCH: 96\n",
            "train_loss:0.000435\n",
            "------------TRAIN------------\n",
            "EPOCH: 97\n",
            "train_loss:0.000148\n",
            "------------TRAIN------------\n",
            "EPOCH: 98\n",
            "train_loss:0.000409\n",
            "------------TRAIN------------\n",
            "EPOCH: 99\n",
            "train_loss:0.001331\n",
            "------------TRAIN------------\n",
            "EPOCH: 100\n",
            "train_loss:0.000362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'set_seed_slowfast.pth')\n",
        "model.load_state_dict(torch.load('set_seed_slowfast.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dNn0i8Rh4v0",
        "outputId": "ca221ad3-df3c-40e9-fd4f-3a093f2e6a13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_pred = np.zeros(0)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for idx, d in enumerate(test_loader):\n",
        "        output = model(d)\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "        total_pred = np.append(total_pred, pred.cpu().numpy())"
      ],
      "metadata": {
        "id": "vgqOrH2d3fIZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit['label'] = total_pred\n",
        "submit.to_csv('set_seed_slowfast_submit.csv', index=False)"
      ],
      "metadata": {
        "id": "efMVArWs3hVp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QDYzMeyN3ncp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}